{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: findspark in /usr/local/lib/python3.7/site-packages (1.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('anamoly_detection').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.format('csv').options(header='true',inferschema='true').load(\"drive_stats_2019_Q1/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.createOrReplaceTempView(\"query_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data : Calculating Annualized failure rate and normalized read error rate , smart attribute 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+\n",
      "|              model|failures|\n",
      "+-------------------+--------+\n",
      "|        ST4000DM000|     107|\n",
      "|      ST12000NM0007|     180|\n",
      "|TOSHIBA MQ01ABF050M|       3|\n",
      "|       ST8000NM0055|      58|\n",
      "|       WDC WD60EFRX|       1|\n",
      "+-------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "failure_bymodel = spark.sql(\"SELECT model, count(*) AS failures \"+\n",
    "                                \"FROM query_data \"+\n",
    "                                \"WHERE failure = 1 \"+\n",
    "                                \"GROUP BY model\")\n",
    "failure_bymodel.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|              model|count|\n",
      "+-------------------+-----+\n",
      "|        ST4000DM000|19785|\n",
      "|      ST12000NM0007|34708|\n",
      "|        ST8000DM005|   25|\n",
      "|TOSHIBA MQ01ABF050M|  377|\n",
      "|       ST8000NM0055|14381|\n",
      "+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_datacount_bymodel = spark.sql(\"SELECT model, count(*) AS count \"+\n",
    "                                \"FROM query_data \"+\n",
    "                                \"WHERE date = '2019-03-31' \"+\n",
    "                                \"GROUP BY model\")\n",
    "total_datacount_bymodel.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+\n",
      "|              model|drive_days|\n",
      "+-------------------+----------+\n",
      "|        ST4000DM000|   1989429|\n",
      "|      ST12000NM0007|   2955025|\n",
      "|        ST8000DM005|      2250|\n",
      "|         ST320LT007|        85|\n",
      "|TOSHIBA MQ01ABF050M|     32624|\n",
      "+-------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drivedays = spark.sql(\"SELECT model, count(*) AS drive_days \"+\n",
    "                                \"FROM query_data \"+\n",
    "                                \"GROUP BY model\")\n",
    "drivedays.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------+-------------------+\n",
      "|               model|drivedays|failures|annual_failure_rate|\n",
      "+--------------------+---------+--------+-------------------+\n",
      "|HGST HMS5C4040ALE640|   313383|       2|           0.232942|\n",
      "|HGST HMS5C4040BLE640|  1172824|      11|           0.342336|\n",
      "|HGST HUH721212ALE600|    14040|       1|           2.599715|\n",
      "|HGST HUH721212ALN604|   259749|       4|           0.562081|\n",
      "|HGST HUH728080ALE600|    93598|       3|           1.169897|\n",
      "+--------------------+---------+--------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_datacount_bymodel.registerTempTable(\"model_count\")\n",
    "failure_bymodel.registerTempTable(\"model_failures\")\n",
    "drivedays.registerTempTable(\"drivedays\")\n",
    "\n",
    "\n",
    "failure_rates = spark.sql(\"SELECT drivedays.model AS model, \"+ \n",
    "                                \"drivedays.drive_days AS drivedays, \"+\n",
    "                                \"model_failures.failures AS failures, \"+\n",
    "                                \"100.0 * (1.0 * failures) / (drive_days / 365.0) AS annual_failure_rate \"+\n",
    "                                \"FROM drivedays, model_failures, model_count \"+\n",
    "                                \"WHERE drivedays.model = model_failures.model \"+\n",
    "                                \"AND model_count.model = model_failures.model \"+\n",
    "                                \"ORDER BY model\")\n",
    "\n",
    "failure_rates.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Annualized_failure_rate model to detect anamoly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_label(value):\n",
    "    if value > 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------+-------------------+-----+\n",
      "|               model|drivedays|failures|annual_failure_rate|label|\n",
      "+--------------------+---------+--------+-------------------+-----+\n",
      "|HGST HMS5C4040ALE640|   313383|       2|           0.232942|    0|\n",
      "|HGST HMS5C4040BLE640|  1172824|      11|           0.342336|    0|\n",
      "|HGST HUH721212ALE600|    14040|       1|           2.599715|    1|\n",
      "|HGST HUH721212ALN604|   259749|       4|           0.562081|    0|\n",
      "|HGST HUH728080ALE600|    93598|       3|           1.169897|    0|\n",
      "|       ST10000NM0086|   108555|       3|           1.008705|    0|\n",
      "|       ST12000NM0007|  2955025|     180|           2.223331|    1|\n",
      "|         ST4000DM000|  1989429|     107|           1.963126|    0|\n",
      "|       ST500LM012 HN|    50619|      12|           8.652877|    1|\n",
      "|          ST500LM030|    14479|       9|          22.688031|    1|\n",
      "|         ST6000DX000|   135832|       1|           0.268714|    0|\n",
      "|         ST8000DM002|   888741|      29|           1.191011|    0|\n",
      "|         ST8000DM004|      273|       1|         133.699670|    1|\n",
      "|        ST8000NM0055|  1294451|      58|           1.635442|    0|\n",
      "| TOSHIBA MG07ACA14TA|   109404|       1|           0.333626|    0|\n",
      "|  TOSHIBA MQ01ABF050|    46969|      14|          10.879516|    1|\n",
      "| TOSHIBA MQ01ABF050M|    32624|       3|           3.356425|    1|\n",
      "|      WDC WD5000LPCX|     4920|       2|          14.837398|    1|\n",
      "|      WDC WD5000LPVX|    22015|       2|           3.315921|    1|\n",
      "|        WDC WD60EFRX|    30523|       1|           1.195820|    0|\n",
      "+--------------------+---------+--------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "udfadd_label = udf(add_label, IntegerType())\n",
    "df_failure_with_label = failure_rates.withColumn(\"label\", udfadd_label(\"annual_failure_rate\"))\n",
    "df_failure_with_label.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------+-------------------+-----+-----------+\n",
      "|               model|drivedays|failures|annual_failure_rate|label|   features|\n",
      "+--------------------+---------+--------+-------------------+-----+-----------+\n",
      "|HGST HMS5C4040ALE640|   313383|       2|           0.232942|    0| [0.232942]|\n",
      "|HGST HMS5C4040BLE640|  1172824|      11|           0.342336|    0| [0.342336]|\n",
      "|HGST HUH721212ALE600|    14040|       1|           2.599715|    1| [2.599715]|\n",
      "|HGST HUH721212ALN604|   259749|       4|           0.562081|    0| [0.562081]|\n",
      "|HGST HUH728080ALE600|    93598|       3|           1.169897|    0| [1.169897]|\n",
      "|       ST10000NM0086|   108555|       3|           1.008705|    0| [1.008705]|\n",
      "|       ST12000NM0007|  2955025|     180|           2.223331|    1| [2.223331]|\n",
      "|         ST4000DM000|  1989429|     107|           1.963126|    0| [1.963126]|\n",
      "|       ST500LM012 HN|    50619|      12|           8.652877|    1| [8.652877]|\n",
      "|          ST500LM030|    14479|       9|          22.688031|    1|[22.688031]|\n",
      "|         ST6000DX000|   135832|       1|           0.268714|    0| [0.268714]|\n",
      "|         ST8000DM002|   888741|      29|           1.191011|    0| [1.191011]|\n",
      "|         ST8000DM004|      273|       1|         133.699670|    1|[133.69967]|\n",
      "|        ST8000NM0055|  1294451|      58|           1.635442|    0| [1.635442]|\n",
      "| TOSHIBA MG07ACA14TA|   109404|       1|           0.333626|    0| [0.333626]|\n",
      "|  TOSHIBA MQ01ABF050|    46969|      14|          10.879516|    1|[10.879516]|\n",
      "| TOSHIBA MQ01ABF050M|    32624|       3|           3.356425|    1| [3.356425]|\n",
      "|      WDC WD5000LPCX|     4920|       2|          14.837398|    1|[14.837398]|\n",
      "|      WDC WD5000LPVX|    22015|       2|           3.315921|    1| [3.315921]|\n",
      "|        WDC WD60EFRX|    30523|       1|           1.195820|    0|  [1.19582]|\n",
      "+--------------------+---------+--------+-------------------+-----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#converting into features and adding labels :  label = 0 if annual_failure_rate < 2 else 1\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "feature_conv = VectorAssembler(inputCols=[\"annual_failure_rate\"], outputCol=\"features\")\n",
    "df_failure = feature_conv.transform(df_failure_with_label)\n",
    "df_failure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- model: string (nullable = true)\n",
      " |-- drivedays: long (nullable = false)\n",
      " |-- failures: long (nullable = false)\n",
      " |-- annual_failure_rate: decimal(38,6) (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_failure.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#splitting the data into train , test and validation\n",
    "train, test, validation = df_failure.randomSplit([0.75, 0.15, 0.10], seed=12345)\n",
    "train.count()\n",
    "#test.count()\n",
    "#validation.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the model using Linear SVM\n",
    "\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "\n",
    "lsvc = LinearSVC(maxIter=10, regParam=0.1)\n",
    "# Fit the model\n",
    "lsvcModel = lsvc.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.0261])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvcModel.coefficients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0089077960181476"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvcModel.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|label|prediction|\n",
      "+-----+----------+\n",
      "|    0|       0.0|\n",
      "|    1|       0.0|\n",
      "+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict = lsvcModel.transform(test)\n",
    "#predict.select(\"prediction\").show()\n",
    "predict.select(\"label\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized Read error rate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+\n",
      "|smart_1_normalized|               model|\n",
      "+------------------+--------------------+\n",
      "|               117|         ST4000DM000|\n",
      "|                80|       ST12000NM0007|\n",
      "|                83|       ST12000NM0007|\n",
      "|                81|       ST12000NM0007|\n",
      "|               100|HGST HMS5C4040ALE640|\n",
      "|                75|        ST8000NM0055|\n",
      "|                83|       ST12000NM0007|\n",
      "|                83|       ST12000NM0007|\n",
      "|                78|       ST12000NM0007|\n",
      "|                77|        ST8000NM0055|\n",
      "|               117|         ST4000DM000|\n",
      "|                81|         ST8000DM002|\n",
      "|                74|       ST12000NM0007|\n",
      "|                80|        ST8000NM0055|\n",
      "|                78|       ST12000NM0007|\n",
      "|               100|HGST HMS5C4040ALE640|\n",
      "|               100|HGST HMS5C4040BLE640|\n",
      "|               100|HGST HMS5C4040BLE640|\n",
      "|               100| TOSHIBA MG07ACA14TA|\n",
      "|               100|HGST HMS5C4040BLE640|\n",
      "+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "normalized_features = data.select(\"smart_1_normalized\",\"model\").filter(data[\"smart_1_normalized\"].isNotNull())\n",
    "normalized_features.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_label_b(value):\n",
    "    if value > 100:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+-----+\n",
      "|smart_1_normalized|               model|label|\n",
      "+------------------+--------------------+-----+\n",
      "|               117|         ST4000DM000|    1|\n",
      "|                80|       ST12000NM0007|    0|\n",
      "|                83|       ST12000NM0007|    0|\n",
      "|                81|       ST12000NM0007|    0|\n",
      "|               100|HGST HMS5C4040ALE640|    0|\n",
      "|                75|        ST8000NM0055|    0|\n",
      "|                83|       ST12000NM0007|    0|\n",
      "|                83|       ST12000NM0007|    0|\n",
      "|                78|       ST12000NM0007|    0|\n",
      "|                77|        ST8000NM0055|    0|\n",
      "|               117|         ST4000DM000|    1|\n",
      "|                81|         ST8000DM002|    0|\n",
      "|                74|       ST12000NM0007|    0|\n",
      "|                80|        ST8000NM0055|    0|\n",
      "|                78|       ST12000NM0007|    0|\n",
      "|               100|HGST HMS5C4040ALE640|    0|\n",
      "|               100|HGST HMS5C4040BLE640|    0|\n",
      "|               100|HGST HMS5C4040BLE640|    0|\n",
      "|               100| TOSHIBA MG07ACA14TA|    0|\n",
      "|               100|HGST HMS5C4040BLE640|    0|\n",
      "+------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "udfadd_label = udf(add_label_b, IntegerType())\n",
    "df_normalized_rate_with_label = normalized_features.withColumn(\"label\", udfadd_label(\"smart_1_normalized\"))\n",
    "df_normalized_rate_with_label.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecAssembler = VectorAssembler(inputCols=[\"smart_1_normalized\"], outputCol=\"features\")\n",
    "normalized_feat_DF = vecAssembler.transform(df_normalized_rate_with_label)\n",
    "#normalized_feat_DF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7181826"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_s, test_s, validation_s = normalized_feat_DF.randomSplit([0.75, 0.15, 0.10], seed=12345)\n",
    "train_s.count()\n",
    "#test_s.count()\n",
    "#validation_s.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc = LinearSVC(maxIter=10, regParam=0.1)\n",
    "# Fit the model\n",
    "lsvcModel = lsvc.fit(train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.004])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvcModel.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.3827678185296213"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvcModel.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|label|prediction|\n",
      "+-----+----------+\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "|    0|       0.0|\n",
      "+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict = lsvcModel.transform(test_s)\n",
    "#predict.select(\"prediction\").show()\n",
    "predict.select(\"label\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
